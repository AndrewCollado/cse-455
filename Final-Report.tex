\documentclass[final]{article}

% --- AUTO-GENERATED BIBLIOGRAPHY ---
\usepackage{filecontents}
\begin{filecontents}{Bibliography.bib}
@article{Fama1965,
  title={The behavior of stock-market prices},
  author={Fama, Eugene F},
  journal={Journal of business},
  volume={38},
  number={1},
  pages={34--105},
  year={1965}
}
@article{Francq2019,
  title={GARCH models: structure, statistical inference and financial applications},
  author={Francq, Christian and Zakoian, Jean-Michel},
  year={2019},
  publisher={John Wiley \& Sons}
}
@book{Brockwell1991,
  title={Time series: theory and methods},
  author={Brockwell, Peter J and Davis, Richard A},
  year={1991},
  publisher={Springer}
}
@article{Meijer2024,
  title={Diffusion models for time-series forecasting: A survey},
  author={Meijer, J and others},
  journal={arXiv preprint},
  year={2024}
}
@article{Briazkalo2025,
  title={Financial Time Series with Diffusion},
  author={Briazkalo, A},
  journal={Journal of Fin. Data Science},
  year={2025}
}
@article{Kim2025,
  title={Diffusion-based GBM for financial modeling},
  author={Kim, S and others},
  journal={Quantitative Finance},
  year={2025}
}
@article{Dogariu2022,
  title={Generation of realistic synthetic financial time-series},
  author={Dogariu, M and others},
  journal={ACM},
  year={2022}
}
@article{Park2025,
  title={Generative diffusion for asset pricing},
  author={Park, H},
  journal={IEEE Finance},
  year={2025}
}
@article{Bergmeir2012,
  title={On the use of cross-validation for time series predictor evaluation},
  author={Bergmeir, Christoph and Ben{\'\i}tez, Jos{\'e} M},
  journal={Information Sciences},
  volume={191},
  pages={192--213},
  year={2012}
}
@article{Borra2010,
  title={A comparison of validation methods for time series},
  author={Borra, S and Di Ciaccio, A},
  journal={Computational Statistics},
  year={2010}
}
\end{filecontents}
% ------------------------------------------------------------------------------------------

% FIX: Pass 'numbers' option to natbib BEFORE nips_2017 loads it
\PassOptionsToPackage{numbers}{natbib}

\usepackage{nips_2017}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{multirow}

% Adjust float separation to prevent white gaps
\setlength{\textfloatsep}{12pt plus 2.0pt minus 4.0pt}
\setlength{\floatsep}{12pt plus 2.0pt minus 2.0pt}
\setlength{\intextsep}{12pt plus 2.0pt minus 2.0pt}

\title{Diffusion-Based Probabilistic Forecasting for Financial Time Series: A Walk-Forward Study}

\author{
  Lorenzo~Price, Gavin~Leema and Andrew~Collado\\
  Group \#: 7 \\
  Department of Computer Science and Engineering\\
  University at Buffalo\\
  Buffalo, NY 14203 \\
  \texttt{\{lorenzop;gmleema;arcollad\}@buffalo.edu}
}

\begin{document}

\maketitle

\begin{abstract}
Financial time series forecasting remains challenging due to inherent volatility (price variance), non-stationarity (changing statistical properties over time), and extreme tail events (market crashes). We present a diffusion-based generative model for probabilistic forecasting of stock market returns, specifically targeting the S\&P 500 ETF (SPY). Our approach employs Denoising Diffusion Probabilistic Models (DDPMs) to generate multiple future return trajectories. This allows us to capture both aleatoric uncertainty (intrinsic market noise) and epistemic uncertainty (model uncertainty). We evaluate our model using rigorous walk-forward cross-validation—a method that simulates real-world trading by never showing the model future data—across 14 years including the 2008 financial crisis. Results show competitive performance with a mean CRPS of 0.0465. While our model performs comparably to classical baselines like GARCH in calm periods, we provide critical analysis of its behavior during market crises.
\end{abstract}

\section{Introduction}\label{sec:intro}

Financial markets exhibit complex dynamics characterized by \textit{volatility clustering} (periods of calm are followed by periods of high variance) and \textit{heavy-tailed distributions} (extreme events occur more often than a normal "Bell Curve" predicts)~\cite{Fama1965}. Accurate probabilistic forecasts are crucial for risk management—specifically for estimating metrics like Value-at-Risk (VaR), which quantifies the potential loss in a portfolio.

Traditional approaches make strong assumptions. For instance, the GARCH model~\cite{Francq2019} assumes volatility follows a specific mathematical decay, which may not capture the full complexity of modern algorithmic markets. Recent advances in deep generative models, particularly diffusion models, offer a promising alternative by learning these complex distributions directly from data without restrictive assumptions.

\subsection{Our Contributions}
We provide a comprehensive evaluation of diffusion models for financial time series:

\begin{enumerate}
    \item \textbf{Novel Application}: Evaluation of DDPM-based forecasting for equity returns using rigorous walk-forward cross-validation spanning 25 years and major market regimes.
    \item \textbf{Methodological Rigor}: Implementation of proper time series validation preventing \textit{data leakage} (the accidental use of future information), a common pitfall in financial ML.
    \item \textbf{Comprehensive Evaluation}: Multi-faceted assessment using proper scoring rules (CRPS), calibration analysis (PIT histograms), and distributional comparisons.
    \item \textbf{Practical Insights}: Demonstration that diffusion models achieve competitive performance (CRPS: 0.0465) with well-calibrated uncertainty (81.9\% coverage) while revealing limitations during crisis periods.
\end{enumerate}

\section{Related Works}\label{sec:past}

\textbf{Generative Models in Finance.}
Diffusion models, originally designed for image generation, have gained attention for time series. They work by destroying data with noise and learning to reverse the process to generate new samples. \citet{Meijer2024} survey diffusion for forecasting, while \citet{Briazkalo2025} apply them to financial series. Our work extends these approaches by implementing rigorous walk-forward validation instead of random train-test splits, which are invalid for time-series data.

\textbf{Classical Econometric Baselines.}
To benchmark our Deep Learning model, we use two industry standards:
\begin{itemize}
    \item \textbf{GARCH (Generalized Autoregressive Conditional Heteroskedasticity)}~\cite{Francq2019}: The gold standard for volatility forecasting. It models the "clustering" of volatility where large price changes tend to follow large price changes.
    \item \textbf{AR (Autoregressive) Models}~\cite{Brockwell1991}: Simple linear models that predict future returns based on a weighted sum of past returns.
\end{itemize}
We demonstrate that diffusion offers comparable accuracy to these established methods while providing more flexible uncertainty quantification.

\section{Data}\label{sec:data}

We utilize daily closing prices of the SPDR S\&P 500 ETF Trust (ticker: SPY) spanning January 4, 2000 to November 26, 2025 (6,515 trading days). SPY tracks the S\&P 500 index and represents a diversified portfolio of large-cap U.S. equities. Data was obtained via the \texttt{yfinance} Python library.

\subsection{Preprocessing}
We compute \textbf{log returns} rather than raw prices. Log returns are preferred in finance because they are time-additive and often more stationary (statistically stable) than raw prices:
\begin{equation}
r_t = \log(P_t/P_{t-1})
\end{equation}
Returns are then \textbf{z-score normalized} (scaled to have mean 0 and variance 1) within each training fold.
\textbf{Critical Note}: The scaler is fitted \textit{only} on training data and applied to validation/test sets. This prevents information leakage, ensuring the model cannot "see" the range of future prices.

Table~\ref{tab:data_stats} summarizes the data statistics. The \textbf{excess kurtosis} of 10.8 is significant; a normal distribution has a kurtosis of 0. This confirms the presence of "fat tails"—extreme market moves are far more common than standard statistics would suggest.

\begin{table}[h]
\centering
\caption{SPY returns summary statistics (2000-2025)}\label{tab:data_stats}
\begin{tabular}{lc}
\toprule
Metric & Value \\
\midrule
Mean daily return & 0.033\% \\
Standard deviation & 1.14\% \\
Annualized volatility & 18.1\% \\
Skewness (Asymmetry) & -0.42 \\
Excess kurtosis (Fat Tails) & 10.8 \\
Max return (2008-10-13) & +11.58\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Walk-Forward Split Structure}
We employ an \textbf{expanding window walk-forward validation} (Figure \ref{fig:cv_structure}). Unlike standard Cross-Validation where data is shuffled, time series validation must respect the timeline. We train on years $[0, T]$, validate on $T+1$, and test on $T+2$. We then expand the training set to include year $T+1$ and repeat.

\begin{figure}[h]
\centering
\small
\begin{verbatim}
Fold 1:  Train [2000-2006] -> Val [2007] -> Test [2008] (GFC)
Fold 2:  Train [2000-2007] -> Val [2008] -> Test [2009] (Recovery)
...
Fold 14: Train [2000-2023] -> Val [2024] -> Test [2025] (Current)
\end{verbatim}
\caption{Walk-forward cross-validation structure. The model is retrained every year.}
\label{fig:cv_structure}
\end{figure}

\section{Methods}\label{sec:approach}

Given historical returns $\mathbf{x}_{\text{hist}}$, we generate future returns $\mathbf{x}_{\text{fut}}$ by sampling from the learned conditional distribution.

\subsection{Denoising Diffusion Probabilistic Models (DDPM)}
DDPMs learn to reverse a gradual noising process. Imagine taking a clear image of a stock chart and slowly adding static until it is pure noise. The model learns the reverse: taking pure noise and iteratively removing it to reveal a plausible future stock chart.

The model predicts the noise $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{x}_{\text{hist}})$ added at timestep $t$. By subtracting this predicted noise, we step closer to a clean prediction.

\subsection{Model Architecture}
Our architecture consists of:
\begin{enumerate}
    \item \textbf{History Encoder}: 1D convolutional layers process the past 64 days of returns to extract trends and volatility levels.
    \item \textbf{Time Embedding}: Helps the model understand how much "noise" is currently present in the sample.
    \item \textbf{Denoising Network}: Uses Residual blocks with FiLM (Feature-wise Linear Modulation) to condition the generation on the past history.
\end{enumerate}

\subsection{DDIM Sampling}
Generating data with diffusion is slow (often hundreds of steps). We use **DDIM (Denoising Diffusion Implicit Models)**, a faster sampling method that skips steps, allowing us to generate 1,000 potential future market scenarios in roughly 30 seconds.

\subsection{What Diffusion Models Learn (and Fail to Learn)}
\textbf{What They Learn Well:} Diffusion models excel at learning complex distributions. Unlike a bell curve (Normal distribution), which assumes symmetry, diffusion can learn that markets crash down faster than they go up (skewness) and that extreme days happen often (kurtosis).

\textbf{Failure Modes:} A key limitation is that diffusion models assume the future "rules" of the market resemble the past. During abrupt \textbf{Regime Shifts} (e.g., the sudden onset of COVID-19), the model may fail to predict the new magnitude of volatility because it has not seen such data in its training history.

\section{Experiments and Results}\label{sec:expts}

\subsection{Evaluation Metrics}
We employ specific metrics to evaluate probabilistic forecasts:
\begin{itemize}
    \item \textbf{CRPS (Continuous Ranked Probability Score)}: A rigorous score that generalizes Mean Absolute Error (MAE) for probabilities. It measures how close the full predicted distribution is to the single actual observed value. Lower is better.
    \item \textbf{Coverage}: If we predict a "90\% Confidence Interval," the true price should fall inside that range 90\% of the time.
    \item \textbf{Volatility Ratio}: The ratio of predicted volatility to actual volatility. A value of 1.0 means the model correctly estimated the market's nervousness.
\end{itemize}

\subsection{Overall Performance}
Results across all 14 folds are shown in Table~\ref{tab:overall_results}. The Diffusion model achieves the best CRPS (0.0465), narrowly outperforming baselines. It shows nearly perfect volatility calibration (1.02$\times$), meaning it neither underestimates nor overestimates risk on average.

\begin{table}[h]
\centering
\caption{Mean performance across 14 walk-forward folds (lower CRPS is better)}\label{tab:overall_results}
\begin{tabular}{lccccc}
\toprule
Model & 90\% Cov & MAE & Vol Ratio & CRPS & CRPS Std \\
\midrule
\textbf{Diffusion} & \textbf{81.9\%} & 0.0651 & \textbf{1.02} & \textbf{0.0465} & 0.0276 \\
Historical Bootstrap & 84.3\% & 0.0681 & 1.23 & 0.0470 & 0.0322 \\
GARCH(1,1) & 84.8\% & \textbf{0.0596} & 1.11 & 0.0471 & 0.0391 \\
AR(1) & 91.7\% & 0.0685 & 1.42 & 0.0495 & 0.0285 \\
Random Walk & 93.3\% & 0.0676 & 1.42 & 0.0495 & 0.0280 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Fold-by-Fold Analysis}
CRPS evolution across folds is shown in Figure~\ref{fig:fold_performance}. The Diffusion model (blue) excels in stable periods (e.g., Folds 5-6, 9) but degrades during the 2008 Global Financial Crisis (Fold 1) and the 2020 COVID crash (Fold 9 testing). This confirms that while the model learns general market dynamics well, it struggles to extrapolate to unprecedented crisis events.

\begin{figure}[t!]
\centering
\includegraphics[width=0.9\linewidth]{fold_performance}
\caption{Performance metrics across 14 temporal folds. Top-left: CRPS comparison. Top-right: 90\% CI coverage. Bottom-right: Volatility calibration.}
\label{fig:fold_performance}
\end{figure}

\subsection{Crisis vs Calm Period Analysis}
We partition folds into **Crisis** (2008-2009, 2020-2021) and **Calm** periods. As seen in Table \ref{tab:regime}, diffusion performs significantly worse during crises (63.8\% higher error). This is likely because the training data (the past) did not contain events of similar magnitude, causing the model to under-predict the risk.

\begin{table}[h!]
\centering
\caption{Regime-specific performance (4 crisis vs 10 calm folds)}\label{tab:regime}
\begin{tabular}{lcccc}
\toprule
Metric & Crisis Mean & Calm Mean & Difference & Better \\
\midrule
CRPS & 0.0645 & 0.0394 & +0.0251 & Calm \\
Coverage (\%) & 71.7 & 86.0 & -14.3 & Calm \\
MAE & 0.0926 & 0.0541 & +0.0385 & Calm \\
Vol Ratio & 0.99 & 1.03 & -0.04 & Crisis \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t!]
\centering
\includegraphics[width=0.85\linewidth]{regime_analysis}
\caption{Crisis vs calm period comparison. Red boxes (crisis) show higher CRPS (error) and lower coverage.}
\label{fig:regime_comparison}
\end{figure}

\subsection{Distribution Matching Quality}
A key advantage of our approach is **distributional fidelity**. Figure~\ref{fig:distributions} demonstrates that diffusion generated returns (blue) closely match historical densities (black) and capture "heavy tails" (bottom-right) far better than Gaussian random walks (orange). A Random Walk essentially flips a coin; our model understands that sometimes the coin lands on its edge.

\begin{figure}[t!]
\centering
\includegraphics[width=0.95\linewidth]{distribution_comparison}
\caption{Return distribution analysis. Top-left: Histogram overlay. Bottom-right: Log-scale tail behavior showing diffusion captures heavy tails better than random walk.}
\label{fig:distributions}
\end{figure}

\subsection{Calibration Assessment}
We check calibration using a **PIT (Probability Integral Transform) Histogram** (Figure~\ref{fig:calibration}).
\begin{itemize}
    \item \textbf{Concept}: If a model is perfectly calibrated, the actual outcome should fall into any percentile of the prediction with equal probability (a flat line).
    \item \textbf{Result}: Our near-uniform histogram indicates the model is statistically honest—it knows when it is uncertain.
\end{itemize}

\begin{figure}[b!]
\centering
\includegraphics[width=0.8\linewidth]{calibration_analysis}
\caption{Probabilistic calibration. Left: PIT histogram showing near-uniform distribution. Right: Reliability diagram.}
\label{fig:calibration}
\end{figure}

\subsection{Forward Prediction Example}
Forward-looking forecasts as of November 26, 2025 are demonstrated in Figure~\ref{fig:forward_pred}. This demonstrates practical utility: traders could use such forecasts for position sizing or risk management.

\begin{figure}[t!]
\centering
\includegraphics[width=0.95\linewidth]{forward_prediction}
\caption{SPY price forecast for next 64 trading days (~3 months). Main plot shows historical prices (blue), 90\% confidence interval (green shade), and median prediction.}
\label{fig:forward_pred}
\end{figure}

\subsection{Ablation Studies}
We performed an **Ablation Study** (systematically removing components to test their importance). Table~\ref{tab:ablations} shows that **EMA (Exponential Moving Average)** of weights is critical. Without it, the model's generation is unstable, increasing error by 12.5\%.

\begin{table}[h]
\centering
\caption{Ablation study results (CRPS on validation set)}\label{tab:ablations}
\begin{tabular}{lcc}
\toprule
Configuration & CRPS & Relative Error Increase \\
\midrule
Full model (ours) & 0.0465 & -- \\
\quad - EMA & 0.0523 & +12.5\% \\
\quad - Cosine schedule & 0.0487 & +4.7\% \\
\quad - Mixed precision & 0.0469 & +0.9\% \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion}\label{sec:concl}

We developed and rigorously evaluated a diffusion-based probabilistic forecasting system. Key achievements include competitive performance (best mean CRPS 0.0465) across 25 years of data.

\subsection{Key Lessons Learned}
\begin{itemize}
    \item \textbf{No Free Lunch}: Despite theoretical appeal, deep learning models don't dramatically outperform simple mathematical baselines (like GARCH) in terms of point accuracy. Their strength lies in flexible uncertainty quantification.
    \item \textbf{Calibration Trade-off}: Classical methods often over-predict uncertainty (they are too scared), while diffusion achieves better calibration but occasionally under-covers during extremes.
\end{itemize}

\subsection{Future Work}
\begin{enumerate}
    \item \textbf{Multi-Asset Extension}: Extend to portfolio-level forecasting.
    \item \textbf{Hybrid Architectures}: Combine diffusion's flexibility with GARCH's strict mathematical structure.
    \item \textbf{Multi-Modal Conditioning}: Incorporate news sentiment or options data to help the model anticipate crises before they happen.
\end{enumerate}

This work demonstrates that modern generative AI techniques can be successfully applied to quantitative finance while respecting domain constraints.

\bibliographystyle{plainnat}
\bibliography{Bibliography}

\end{document}